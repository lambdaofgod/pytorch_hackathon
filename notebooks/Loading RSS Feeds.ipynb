{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp rss_feeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import bs4\n",
    "import feedparser\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/piotr/Documents/pytorch_hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS Feeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "medium_publications = [\n",
    "    'the-artificial-impostor',\n",
    "    'pytorch',\n",
    "    'dair.ai',\n",
    "    'towards-artificial-intelligence',\n",
    "    'swlh',\n",
    "    '@ODSC',\n",
    "    'doctrine',\n",
    "    'paperswithcode'\n",
    "]\n",
    "\n",
    "\n",
    "medium_url_template = 'https://medium.com/feed/{}'\n",
    "medium_url = medium_url_template.format(medium_publications[0])\n",
    "medium_urls = [medium_url_template.format(publication) for publication in medium_publications]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "subreddits = [\n",
    "    'MachineLearning',\n",
    "    'deeplearning',\n",
    "    'datascience',\n",
    "    'cognitivelinguistics',\n",
    "    'TopOfArxivSanity',\n",
    "    'kaggle'\n",
    "]\n",
    "\n",
    "reddit_url_template = 'https://www.reddit.com/r/{}/.rss'\n",
    "reddit_url = reddit_url_template.format(subreddits[0])\n",
    "reddit_urls = [reddit_url_template.format(subreddit) for subreddit in subreddits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_article_text(article):\n",
    "    article_html_content = article['content'][0]['value']\n",
    "    article_text = bs4.BeautifulSoup(article_html_content).text\n",
    "    return article_text\n",
    "\n",
    "\n",
    "def get_feed_article_texts(feed):\n",
    "    return [get_article_text(article) for article in feed['entries'] if 'content' in article.keys()]\n",
    "\n",
    "\n",
    "def get_feed_article_df(feed):\n",
    "    feed_df = pd.DataFrame.from_records(feed['entries'])\n",
    "    feed_df['text'] = feed_df['summary'].apply(lambda s: bs4.BeautifulSoup(s).text)\n",
    "    return feed_df\n",
    "\n",
    "\n",
    "def add_field(df, field_name, values):\n",
    "    df[field_name] = values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "paperswithcode_url = 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest' \n",
    "hackernews_url = 'https://news.ycombinator.com/rss' \n",
    "rss_feed_urls = [paperswithcode_url, hackernews_url] + medium_urls + reddit_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_urls = pd.read_table('data/feeds.txt', header=None).iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest\n",
      "https://news.ycombinator.com/rss\n",
      "https://medium.com/feed/the-artificial-impostor\n",
      "https://medium.com/feed/pytorch\n",
      "https://medium.com/feed/dair.ai\n",
      "https://medium.com/feed/towards-artificial-intelligence\n",
      "https://medium.com/feed/swlh\n",
      "https://medium.com/feed/@ODSC\n",
      "https://medium.com/feed/doctrine\n",
      "https://medium.com/feed/paperswithcode\n",
      "https://www.reddit.com/r/MachineLearning/.rss\n",
      "https://www.reddit.com/r/deeplearning/.rss\n",
      "https://www.reddit.com/r/datascience/.rss\n",
      "https://www.reddit.com/r/cognitivelinguistics/.rss\n",
      "https://www.reddit.com/r/TopOfArxivSanity/.rss\n",
      "https://www.reddit.com/r/kaggle/.rss\n"
     ]
    }
   ],
   "source": [
    "for url in rss_feed_urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading RSS feed articles to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_feed_df(feed_urls):\n",
    "    feeds = [\n",
    "        (feed_url, feedparser.parse(feed_url))\n",
    "        for feed_url in tqdm.tqdm(feed_urls)\n",
    "    ]\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            add_field(get_feed_article_df(feed), 'feed', feed_url)\n",
    "            for (feed_url, feed) in feeds\n",
    "            if len(feed['entries']) > 0\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df['date'] = df['updated']\n",
    "    df['date'] = df['date'].fillna(df['published'])\n",
    "    \n",
    "    return df\n",
    "#feedparser.parse('https://news.ycombinator.com/rss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:09<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "feed_df = get_feed_df(rss_feed_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 23)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>comments</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>content</th>\n",
       "      <th>href</th>\n",
       "      <th>media_thumbnail</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automated Temporal Equilibrium Analysis: Verification and Synthesis of Multi-Player Games</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Automated Temporal Equilibrium Analysis: Verification and Synthesis of Multi-Player Games'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/automated-temporal-equilibrium-analysis'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/automated-temporal-equilibrium-analysis</td>\n",
       "      <td>In the context of multi-agent systems, the rational verification problem is concerned with checking which temporal logic properties will hold in a system when its constituent agents are assumed to behave rationally and strategically in pursuit of...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'In the context of multi-agent systems, the rational verification problem is concerned with checking which temporal logic properti...</td>\n",
       "      <td>https://paperswithcode.com/paper/automated-temporal-equilibrium-analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In the context of multi-agent systems, the rational verification problem is concerned with checking which temporal logic properties will hold in a system when its constituent agents are assumed to behave rationally and strategically in pursuit of...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Revisiting Temporal Modeling for Video Super-resolution</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Revisiting Temporal Modeling for Video Super-resolution'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/revisiting-temporal-modeling-for-video-super'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/revisiting-temporal-modeling-for-video-super</td>\n",
       "      <td>Video super-resolution plays an important role in surveillance video analysis and ultra-high-definition video display, which has drawn much attention in both the research and industrial communities. &lt;p&gt;Code: &lt;a href=\"https://github.com/junpan19/R...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Video super-resolution plays an important role in surveillance video analysis and ultra-high-definition video display, which has ...</td>\n",
       "      <td>https://paperswithcode.com/paper/revisiting-temporal-modeling-for-video-super</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Video super-resolution', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Video super-resolution plays an important role in surveillance video analysis and ultra-high-definition video display, which has drawn much attention in both the research and industrial communities. Code: https://github.com/junpan19/RRN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/learning-temporally-invariant-and-localizable'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/learning-temporally-invariant-and-localizable</td>\n",
       "      <td>Based on our novel temporal data augmentation algorithms, video recognition performances are improved using only a limited amount of training data compared to the spatial-only data augmentation algorithms, including the 1st Visual Inductive Prior...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Based on our novel temporal data augmentation algorithms, video recognition performances are improved using only a limited amount...</td>\n",
       "      <td>https://paperswithcode.com/paper/learning-temporally-invariant-and-localizable</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Action recognition', 'scheme': None, 'label': None}, {'term': 'Data augmentation', 'scheme': None, 'label': None}, {'term': 'Video recognition', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Based on our novel temporal data augmentation algorithms, video recognition performances are improved using only a limited amount of training data compared to the spatial-only data augmentation algorithms, including the 1st Visual Inductive Prior...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention</td>\n",
       "      <td>However, most existing works focus only on video dynamic information (i. e., motion information) but ignore the specific postures that an athlete is performing in a video, which is important for action assessment in long videos. &lt;p&gt;Code: &lt;a href=...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'However, most existing works focus only on video dynamic information (i. e., motion information) but ignore the specific postures...</td>\n",
       "      <td>https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Action quality assessment', 'scheme': None, 'label': None}]</td>\n",
       "      <td>However, most existing works focus only on video dynamic information (i. e., motion information) but ignore the specific postures that an athlete is performing in a video, which is important for action assessment in long videos. Code: https://git...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weakly Supervised Generative Network for Multiple 3D Human Pose Hypotheses</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Weakly Supervised Generative Network for Multiple 3D Human Pose Hypotheses'}</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/weakly-supervised-generative-network-for'}]</td>\n",
       "      <td>https://paperswithcode.com/paper/weakly-supervised-generative-network-for</td>\n",
       "      <td>In this paper, we propose a weakly supervised deep generative network to address the inverse problem and circumvent the need for ground truth 2D-to-3D correspondences. &lt;p&gt;Code: &lt;a href=\"https://github.com/chaneyddtt/weakly-supervised-3d-pose-gene...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'In this paper, we propose a weakly supervised deep generative network to address the inverse problem and circumvent the need for ...</td>\n",
       "      <td>https://paperswithcode.com/paper/weakly-supervised-generative-network-for</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': '3d human pose estimation', 'scheme': None, 'label': None}]</td>\n",
       "      <td>In this paper, we propose a weakly supervised deep generative network to address the inverse problem and circumvent the need for ground truth 2D-to-3D correspondences. Code: https://github.com/chaneyddtt/weakly-supervised-3d-pose-generator</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                title  \\\n",
       "0           Automated Temporal Equilibrium Analysis: Verification and Synthesis of Multi-Player Games   \n",
       "1                                             Revisiting Temporal Modeling for Video Super-resolution   \n",
       "2  Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition   \n",
       "3          Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos   \n",
       "4                          Weakly Supervised Generative Network for Multiple 3D Human Pose Hypotheses   \n",
       "\n",
       "                                                                                                                                                                                                                 title_detail  \\\n",
       "0           {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Automated Temporal Equilibrium Analysis: Verification and Synthesis of Multi-Player Games'}   \n",
       "1                                             {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Revisiting Temporal Modeling for Video Super-resolution'}   \n",
       "2  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition'}   \n",
       "3          {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos'}   \n",
       "4                          {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Weakly Supervised Generative Network for Multiple 3D Human Pose Hypotheses'}   \n",
       "\n",
       "                                                                                                                                   links  \\\n",
       "0        [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/automated-temporal-equilibrium-analysis'}]   \n",
       "1   [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/revisiting-temporal-modeling-for-video-super'}]   \n",
       "2  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/learning-temporally-invariant-and-localizable'}]   \n",
       "3  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention'}]   \n",
       "4       [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/weakly-supervised-generative-network-for'}]   \n",
       "\n",
       "                                                                             link  \\\n",
       "0        https://paperswithcode.com/paper/automated-temporal-equilibrium-analysis   \n",
       "1   https://paperswithcode.com/paper/revisiting-temporal-modeling-for-video-super   \n",
       "2  https://paperswithcode.com/paper/learning-temporally-invariant-and-localizable   \n",
       "3  https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention   \n",
       "4       https://paperswithcode.com/paper/weakly-supervised-generative-network-for   \n",
       "\n",
       "                                                                                                                                                                                                                                                     summary  \\\n",
       "0  In the context of multi-agent systems, the rational verification problem is concerned with checking which temporal logic properties will hold in a system when its constituent agents are assumed to behave rationally and strategically in pursuit of...   \n",
       "1  Video super-resolution plays an important role in surveillance video analysis and ultra-high-definition video display, which has drawn much attention in both the research and industrial communities. <p>Code: <a href=\"https://github.com/junpan19/R...   \n",
       "2  Based on our novel temporal data augmentation algorithms, video recognition performances are improved using only a limited amount of training data compared to the spatial-only data augmentation algorithms, including the 1st Visual Inductive Prior...   \n",
       "3  However, most existing works focus only on video dynamic information (i. e., motion information) but ignore the specific postures that an athlete is performing in a video, which is important for action assessment in long videos. <p>Code: <a href=...   \n",
       "4  In this paper, we propose a weakly supervised deep generative network to address the inverse problem and circumvent the need for ground truth 2D-to-3D correspondences. <p>Code: <a href=\"https://github.com/chaneyddtt/weakly-supervised-3d-pose-gene...   \n",
       "\n",
       "                                                                                                                                                                                                                                              summary_detail  \\\n",
       "0  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'In the context of multi-agent systems, the rational verification problem is concerned with checking which temporal logic properti...   \n",
       "1  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Video super-resolution plays an important role in surveillance video analysis and ultra-high-definition video display, which has ...   \n",
       "2  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'Based on our novel temporal data augmentation algorithms, video recognition performances are improved using only a limited amount...   \n",
       "3  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'However, most existing works focus only on video dynamic information (i. e., motion information) but ignore the specific postures...   \n",
       "4  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pwc/latest', 'value': 'In this paper, we propose a weakly supervised deep generative network to address the inverse problem and circumvent the need for ...   \n",
       "\n",
       "                                                                               id  \\\n",
       "0        https://paperswithcode.com/paper/automated-temporal-equilibrium-analysis   \n",
       "1   https://paperswithcode.com/paper/revisiting-temporal-modeling-for-video-super   \n",
       "2  https://paperswithcode.com/paper/learning-temporally-invariant-and-localizable   \n",
       "3  https://paperswithcode.com/paper/hybrid-dynamic-static-context-aware-attention   \n",
       "4       https://paperswithcode.com/paper/weakly-supervised-generative-network-for   \n",
       "\n",
       "  guidislink  \\\n",
       "0      False   \n",
       "1      False   \n",
       "2      False   \n",
       "3      False   \n",
       "4      False   \n",
       "\n",
       "                                                                                                                                                                                          tags  \\\n",
       "0                                                                                                                                                                                          NaN   \n",
       "1                                                                                                                          [{'term': 'Video super-resolution', 'scheme': None, 'label': None}]   \n",
       "2  [{'term': 'Action recognition', 'scheme': None, 'label': None}, {'term': 'Data augmentation', 'scheme': None, 'label': None}, {'term': 'Video recognition', 'scheme': None, 'label': None}]   \n",
       "3                                                                                                                       [{'term': 'Action quality assessment', 'scheme': None, 'label': None}]   \n",
       "4                                                                                                                        [{'term': '3d human pose estimation', 'scheme': None, 'label': None}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                        text  \\\n",
       "0  In the context of multi-agent systems, the rational verification problem is concerned with checking which temporal logic properties will hold in a system when its constituent agents are assumed to behave rationally and strategically in pursuit of...   \n",
       "1               Video super-resolution plays an important role in surveillance video analysis and ultra-high-definition video display, which has drawn much attention in both the research and industrial communities. Code: https://github.com/junpan19/RRN   \n",
       "2  Based on our novel temporal data augmentation algorithms, video recognition performances are improved using only a limited amount of training data compared to the spatial-only data augmentation algorithms, including the 1st Visual Inductive Prior...   \n",
       "3  However, most existing works focus only on video dynamic information (i. e., motion information) but ignore the specific postures that an athlete is performing in a video, which is important for action assessment in long videos. Code: https://git...   \n",
       "4            In this paper, we propose a weakly supervised deep generative network to address the inverse problem and circumvent the need for ground truth 2D-to-3D correspondences. Code: https://github.com/chaneyddtt/weakly-supervised-3d-pose-generator   \n",
       "\n",
       "   ... comments authors author author_detail updated updated_parsed content  \\\n",
       "0  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "1  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "2  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "3  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "4  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "\n",
       "  href media_thumbnail date  \n",
       "0  NaN             NaN  NaN  \n",
       "1  NaN             NaN  NaN  \n",
       "2  NaN             NaN  NaN  \n",
       "3  NaN             NaN  NaN  \n",
       "4  NaN             NaN  NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
