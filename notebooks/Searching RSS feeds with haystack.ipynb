{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp haystack_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "\n",
    "import haystack\n",
    "from haystack import database\n",
    "import haystack.database.memory\n",
    "\n",
    "from haystack.retriever.dense import EmbeddingRetriever\n",
    "from pytorch_hackathon import rss_feeds\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/piotr/Documents/pytorch_hackathon\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feeds.txt  topics.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss_feed_urls = list(pd.read_table('data/feeds.txt', header=None).iloc[:,0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  2.00it/s]\n",
      "/home/kuba/Projects/pytorch_hackathon/pytorch_hackathon/rss_feeds.py:63: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 63 of the file /home/kuba/Projects/pytorch_hackathon/pytorch_hackathon/rss_feeds.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  feed_df['text'] = feed_df['summary'].apply(lambda s: bs4.BeautifulSoup(s).text)\n"
     ]
    }
   ],
   "source": [
    "feed_df = rss_feeds.get_feed_df(rss_feed_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>links</th>\n",
       "      <th>link</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>...</th>\n",
       "      <th>comments</th>\n",
       "      <th>authors</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>content</th>\n",
       "      <th>href</th>\n",
       "      <th>media_thumbnail</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adversarial Attack and Defense Strategies for Deep Speaker Recognition Systems</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/adversarial...</td>\n",
       "      <td>https://paperswithcode.com/paper/adversarial-attack-and-defense-strategies-for</td>\n",
       "      <td>Robust speaker recognition, including in the presence of malicious attacks, is becoming increasi...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/adversarial-attack-and-defense-strategies-for</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Adversarial attack', 'scheme': None, 'label': None}, {'term': 'Adversarial training',...</td>\n",
       "      <td>Robust speaker recognition, including in the presence of malicious attacks, is becoming increasi...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We present PARADE, an end-to-end Transformer-based model that considers document-level context f...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Knowledge Transfer via Dense Cross-Layer Mutual-Distillation</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/knowledge-t...</td>\n",
       "      <td>https://paperswithcode.com/paper/knowledge-transfer-via-dense-cross-layer</td>\n",
       "      <td>Knowledge Distillation (KD) based methods adopt the one-way Knowledge Transfer (KT) scheme in wh...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/knowledge-transfer-via-dense-cross-layer</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Representation learning', 'scheme': None, 'label': None}, {'term': 'Transfer learning...</td>\n",
       "      <td>Knowledge Distillation (KD) based methods adopt the one-way Knowledge Transfer (KT) scheme in wh...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral Face Game Character Auto-Creation via PokerFace-GAN</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/neutral-fac...</td>\n",
       "      <td>https://paperswithcode.com/paper/neutral-face-game-character-auto-creation-via</td>\n",
       "      <td>Besides, the neural network based renderer used in previous methods is also difficult to be exte...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/neutral-face-game-character-auto-creation-via</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Adversarial training', 'scheme': None, 'label': None}, {'term': 'Self-supervised lear...</td>\n",
       "      <td>Besides, the neural network based renderer used in previous methods is also difficult to be exte...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The transferability of adversarial examples across deep neural network (DNN) models is the crux ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP-Loss for Accurate One-Stage Object Detection</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/ap-loss-for...</td>\n",
       "      <td>https://paperswithcode.com/paper/ap-loss-for-accurate-one-stage-object</td>\n",
       "      <td>This paper alleviates this issue by proposing a novel framework to replace the classification ta...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/ap-loss-for-accurate-one-stage-object</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Object detection', 'scheme': None, 'label': None}]</td>\n",
       "      <td>This paper alleviates this issue by proposing a novel framework to replace the classification ta...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeepGIN: Deep Generative Inpainting Network for Extreme Image Inpainting</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...</td>\n",
       "      <td>[{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/deepgin-dee...</td>\n",
       "      <td>https://paperswithcode.com/paper/deepgin-deep-generative-inpainting-network</td>\n",
       "      <td>Existing image inpainting approaches usually encounter difficulties in completing the missing pa...</td>\n",
       "      <td>{'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...</td>\n",
       "      <td>https://paperswithcode.com/paper/deepgin-deep-generative-inpainting-network</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'term': 'Image inpainting', 'scheme': None, 'label': None}]</td>\n",
       "      <td>Existing image inpainting approaches usually encounter difficulties in completing the missing pa...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            title  \\\n",
       "0  Adversarial Attack and Defense Strategies for Deep Speaker Recognition Systems   \n",
       "1                    Knowledge Transfer via Dense Cross-Layer Mutual-Distillation   \n",
       "2                     Neutral Face Game Character Auto-Creation via PokerFace-GAN   \n",
       "3                                 AP-Loss for Accurate One-Stage Object Detection   \n",
       "4        DeepGIN: Deep Generative Inpainting Network for Extreme Image Inpainting   \n",
       "\n",
       "                                                                                          title_detail  \\\n",
       "0  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "1  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "2  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "3  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "4  {'type': 'text/plain', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/p...   \n",
       "\n",
       "                                                                                                 links  \\\n",
       "0  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/adversarial...   \n",
       "1  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/knowledge-t...   \n",
       "2  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/neutral-fac...   \n",
       "3  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/ap-loss-for...   \n",
       "4  [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://paperswithcode.com/paper/deepgin-dee...   \n",
       "\n",
       "                                                                             link  \\\n",
       "0  https://paperswithcode.com/paper/adversarial-attack-and-defense-strategies-for   \n",
       "1       https://paperswithcode.com/paper/knowledge-transfer-via-dense-cross-layer   \n",
       "2  https://paperswithcode.com/paper/neutral-face-game-character-auto-creation-via   \n",
       "3          https://paperswithcode.com/paper/ap-loss-for-accurate-one-stage-object   \n",
       "4     https://paperswithcode.com/paper/deepgin-deep-generative-inpainting-network   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  Robust speaker recognition, including in the presence of malicious attacks, is becoming increasi...   \n",
       "1  Knowledge Distillation (KD) based methods adopt the one-way Knowledge Transfer (KT) scheme in wh...   \n",
       "2  Besides, the neural network based renderer used in previous methods is also difficult to be exte...   \n",
       "3  This paper alleviates this issue by proposing a novel framework to replace the classification ta...   \n",
       "4  Existing image inpainting approaches usually encounter difficulties in completing the missing pa...   \n",
       "\n",
       "                                                                                        summary_detail  \\\n",
       "0  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "1  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "2  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "3  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "4  {'type': 'text/html', 'language': None, 'base': 'https://us-east1-ml-feeds.cloudfunctions.net/pw...   \n",
       "\n",
       "                                                                               id  \\\n",
       "0  https://paperswithcode.com/paper/adversarial-attack-and-defense-strategies-for   \n",
       "1       https://paperswithcode.com/paper/knowledge-transfer-via-dense-cross-layer   \n",
       "2  https://paperswithcode.com/paper/neutral-face-game-character-auto-creation-via   \n",
       "3          https://paperswithcode.com/paper/ap-loss-for-accurate-one-stage-object   \n",
       "4     https://paperswithcode.com/paper/deepgin-deep-generative-inpainting-network   \n",
       "\n",
       "  guidislink  \\\n",
       "0      False   \n",
       "1      False   \n",
       "2      False   \n",
       "3      False   \n",
       "4      False   \n",
       "\n",
       "                                                                                                  tags  \\\n",
       "0  [{'term': 'Adversarial attack', 'scheme': None, 'label': None}, {'term': 'Adversarial training',...   \n",
       "1  [{'term': 'Representation learning', 'scheme': None, 'label': None}, {'term': 'Transfer learning...   \n",
       "2  [{'term': 'Adversarial training', 'scheme': None, 'label': None}, {'term': 'Self-supervised lear...   \n",
       "3                                        [{'term': 'Object detection', 'scheme': None, 'label': None}]   \n",
       "4                                        [{'term': 'Image inpainting', 'scheme': None, 'label': None}]   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Robust speaker recognition, including in the presence of malicious attacks, is becoming increasi...   \n",
       "1  Knowledge Distillation (KD) based methods adopt the one-way Knowledge Transfer (KT) scheme in wh...   \n",
       "2  Besides, the neural network based renderer used in previous methods is also difficult to be exte...   \n",
       "3  This paper alleviates this issue by proposing a novel framework to replace the classification ta...   \n",
       "4  Existing image inpainting approaches usually encounter difficulties in completing the missing pa...   \n",
       "\n",
       "   ... comments authors author author_detail updated updated_parsed content  \\\n",
       "0  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "1  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "2  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "3  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "4  ...      NaN     NaN    NaN           NaN     NaN            NaN     NaN   \n",
       "\n",
       "  href media_thumbnail        date  \n",
       "0  NaN             NaN  2020-08-23  \n",
       "1  NaN             NaN  2020-08-23  \n",
       "2  NaN             NaN  2020-08-23  \n",
       "3  NaN             NaN  2020-08-23  \n",
       "4  NaN             NaN  2020-08-23  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "class Searcher:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name,\n",
    "        text_col,\n",
    "        use_gpu,\n",
    "        max_document_length=256,\n",
    "        quantize_model=True,\n",
    "        document_store_cls=database.memory.InMemoryDocumentStore\n",
    "    ):\n",
    "        self.text_col = text_col\n",
    "        self.embedding_col = text_col + '_emb'\n",
    "        self.max_document_length = max_document_length\n",
    "        self.model_name = model_name\n",
    "        self.document_store = document_store_cls(\n",
    "            embedding_field=self.embedding_col,\n",
    "        )\n",
    "        self.retriever = self._setup_retriever(use_gpu, quantize_model)\n",
    "\n",
    "    def _setup_retriever(self, use_gpu, quantize_model):\n",
    "        retriever = EmbeddingRetriever(\n",
    "            document_store=self.document_store,\n",
    "            embedding_model=self.model_name,\n",
    "            use_gpu=use_gpu)\n",
    "        if not use_gpu and quantize_model:\n",
    "            self.set_quantized_model(retriever)\n",
    "            \n",
    "        return retriever\n",
    "\n",
    "    def add_texts(\n",
    "        self,\n",
    "        df\n",
    "    ):\n",
    "        truncated_texts = [\n",
    "            ' '.join(tokenize.wordpunct_tokenize(text)[:self.max_document_length])\n",
    "            for text in df[self.text_col] \n",
    "        ]\n",
    "        article_embeddings = self.retriever.embed_queries(\n",
    "            texts=truncated_texts\n",
    "        )\n",
    "\n",
    "        df[self.embedding_col] = article_embeddings\n",
    "        self.document_store.write_documents(df.to_dict(orient='records'))\n",
    "    \n",
    "    def search(self, query, top_k=10, **kwargs):\n",
    "        if type(self.document_store) is database.elasticsearch.ElasticsearchDocumentStore:\n",
    "            querying_fn = self.document_store.query \n",
    "        elif type(self.document_store) is database.memory.InMemoryDocumentStore:\n",
    "            querying_fn = self.retriever.retrieve\n",
    "        return querying_fn(\n",
    "            query,\n",
    "            top_k=top_k,\n",
    "            **kwargs\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def set_quantized_model(cls, retriever):\n",
    "        quantized_model = torch.quantization.quantize_dynamic(\n",
    "            retriever.embedding_model.model,\n",
    "            {torch.nn.Linear}, dtype=torch.qint8\n",
    "        )\n",
    "        retriever.embedding_model.model = quantized_model\n",
    "        \n",
    "    @classmethod \n",
    "    def sigmoid(cls, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    @classmethod\n",
    "    def doc_to_dict(cls, doc):\n",
    "        d = {}\n",
    "        d['text'] = doc.text\n",
    "        d['title'] = doc.meta['title']\n",
    "        d['score'] = doc.query_score\n",
    "        d['link'] = doc.meta['link']\n",
    "        d['date'] = doc.meta['date']\n",
    "        return d\n",
    "\n",
    "    def get_topic_score_df(self, raw_results, topic_strings):\n",
    "        topic_query_strings = [\n",
    "            'text is about {}'.format(topic)\n",
    "            for topic in topic_strings\n",
    "        ]\n",
    "\n",
    "        results = [\n",
    "            self.doc_to_dict(doc)\n",
    "            for doc in raw_results \n",
    "        ]\n",
    "        result_embeddings = np.array([\n",
    "            doc.meta['text_emb']\n",
    "            for doc in raw_results\n",
    "        ]).astype('float32')\n",
    "        topic_query_embeddings = np.array(self.retriever.embed_passages(\n",
    "            list(topic_strings)\n",
    "        )).astype('float32')\n",
    "\n",
    "        scores_df = pd.DataFrame({})\n",
    "        scores_df['title'] = list(map(itemgetter('title'), results))\n",
    "        scores_df['text'] = list(map(itemgetter('text'), results))\n",
    "        scores_df['link'] = list(map(itemgetter('link'), results))\n",
    "        scores_df['date'] = list(map(itemgetter('date'), results))\n",
    "\n",
    "        scores = pd.DataFrame(metrics.pairwise.cosine_similarity(\n",
    "            result_embeddings,\n",
    "            topic_query_embeddings\n",
    "        ))\n",
    "        scores.columns = topic_strings\n",
    "\n",
    "        scores_df = pd.concat(\n",
    "            [scores_df, self.sigmoid(scores)],\n",
    "            axis=1\n",
    "        )\n",
    "        return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    \"deepset/sentence_bert\",\n",
    "    \"sentence-transformers/bert-base-nli-mean-tokens\",\n",
    "    \"sentence-transformers/bert-large-nli-mean-tokens\",\n",
    "    \"sentence-transformers/bert-base-nli-max-tokens\",\n",
    "    \"sentence-transformers/bert-base-nli-stsb-mean-tokens\",\n",
    "    \"sentence-transformers/distilbert-base-nli-stsb-mean-tokens\",\n",
    "    \"sentence-transformers/roberta-base-nli-stsb-mean-tokens\",\n",
    "    \"sentence-transformers/roberta-large-nli-stsb-mean-tokens\",\n",
    "    \"sentence-transformers/bert-base-nli-cls-token\",\n",
    "    \"sentence-transformers/distilbert-base-nli-stsb-quora-ranking\",\n",
    "    \"sentence-transformers/bert-large-nli-cls-token\",\n",
    "    \"sentence-transformers/bert-large-nli-max-tokens\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/sentence_bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = Searcher(\n",
    "    model_name,\n",
    "    'text',\n",
    "    use_gpu=use_gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 74/74 [00:10<00:00,  7.19 Batches/s]\n",
      "/etc/conda/envs/ml/lib/python3.7/site-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "searcher.add_texts(feed_df[['text', 'title', 'link']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_texts = feed_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_strings = pd.read_table('data/topics.txt', header=None).iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep learning\n",
      "natural language processing\n",
      "computer vision\n",
      "statistics\n",
      "implementation\n",
      "visualization\n",
      "industry\n",
      "software engineering\n",
      "reddit question\n",
      "arxiv\n",
      "cloud computing\n",
      "deployment\n",
      "competitions\n",
      "business\n",
      "business intelligence\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(topic_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_query_strings = [\n",
    "    'text is about {}'.format(topic)\n",
    "    for topic in topic_strings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 31.56 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "raw_results = searcher.search(\n",
    "    topic_query_strings[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 4/4 [00:00<00:00,  7.63 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "scores_df = searcher.get_topic_score_df(raw_results, topic_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col3 {\n",
       "            background-color:  #d4f6d4;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col4 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col5 {\n",
       "            background-color:  #2b982b;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col6 {\n",
       "            background-color:  #3ea23e;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col7 {\n",
       "            background-color:  #6dbc6d;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col8 {\n",
       "            background-color:  #289628;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col9 {\n",
       "            background-color:  #61b661;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col10 {\n",
       "            background-color:  #84c984;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col11 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col12 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col13 {\n",
       "            background-color:  #2b982b;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col14 {\n",
       "            background-color:  #4daa4d;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col15 {\n",
       "            background-color:  #8fcf8f;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col16 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col17 {\n",
       "            background-color:  #9ed79e;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col3 {\n",
       "            background-color:  #bbe8bb;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col4 {\n",
       "            background-color:  #aee0ae;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col5 {\n",
       "            background-color:  #a8dda8;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col6 {\n",
       "            background-color:  #c1ebc1;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col7 {\n",
       "            background-color:  #a1d9a1;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col8 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col9 {\n",
       "            background-color:  #76c176;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col10 {\n",
       "            background-color:  #1a8e1a;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col11 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col12 {\n",
       "            background-color:  #95d395;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col13 {\n",
       "            background-color:  #9ed89e;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col14 {\n",
       "            background-color:  #99d599;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col15 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col16 {\n",
       "            background-color:  #71bf71;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col17 {\n",
       "            background-color:  #57b057;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col3 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col4 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col5 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col6 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col7 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col8 {\n",
       "            background-color:  #defbde;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col9 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col10 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col11 {\n",
       "            background-color:  #53ae53;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col12 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col13 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col14 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col15 {\n",
       "            background-color:  #92d192;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col16 {\n",
       "            background-color:  #d0f3d0;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col17 {\n",
       "            background-color:  #e5ffe5;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col3 {\n",
       "            background-color:  #4ba94b;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col4 {\n",
       "            background-color:  #70be70;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col5 {\n",
       "            background-color:  #66b866;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col6 {\n",
       "            background-color:  #dcfadc;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col7 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col8 {\n",
       "            background-color:  #048204;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col9 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col10 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col11 {\n",
       "            background-color:  #2d992d;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col12 {\n",
       "            background-color:  #64b764;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col13 {\n",
       "            background-color:  #1f911f;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col14 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col15 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col16 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col17 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col3 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col4 {\n",
       "            background-color:  #70be70;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col5 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col6 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col7 {\n",
       "            background-color:  #5db35d;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col8 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col9 {\n",
       "            background-color:  #4aa94a;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col10 {\n",
       "            background-color:  #2a972a;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col11 {\n",
       "            background-color:  #5eb45e;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col12 {\n",
       "            background-color:  #96d396;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col13 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col14 {\n",
       "            background-color:  #94d294;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col15 {\n",
       "            background-color:  #99d599;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col16 {\n",
       "            background-color:  #98d498;\n",
       "            color:  #000000;\n",
       "        }    #T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col17 {\n",
       "            background-color:  #4dab4d;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >title</th>        <th class=\"col_heading level0 col1\" >text</th>        <th class=\"col_heading level0 col2\" >link</th>        <th class=\"col_heading level0 col3\" >deep learning</th>        <th class=\"col_heading level0 col4\" >natural language processing</th>        <th class=\"col_heading level0 col5\" >computer vision</th>        <th class=\"col_heading level0 col6\" >statistics</th>        <th class=\"col_heading level0 col7\" >implementation</th>        <th class=\"col_heading level0 col8\" >visualization</th>        <th class=\"col_heading level0 col9\" >industry</th>        <th class=\"col_heading level0 col10\" >software engineering</th>        <th class=\"col_heading level0 col11\" >reddit question</th>        <th class=\"col_heading level0 col12\" >arxiv</th>        <th class=\"col_heading level0 col13\" >cloud computing</th>        <th class=\"col_heading level0 col14\" >deployment</th>        <th class=\"col_heading level0 col15\" >competitions</th>        <th class=\"col_heading level0 col16\" >business</th>        <th class=\"col_heading level0 col17\" >business intelligence</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col0\" class=\"data row0 col0\" >Do Not Disturb Me: Person Re-identification Under the Interference of Other Pedestrians</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col1\" class=\"data row0 col1\" >In the conventional person Re-ID setting, it is widely assumed that cropped person images are for each individual. Code: https://github.com/X-BrainLab/PI-ReID</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col2\" class=\"data row0 col2\" >https://paperswithcode.com/paper/do-not-disturb-me-person-re-identification</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col3\" class=\"data row0 col3\" >0.561312</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col4\" class=\"data row0 col4\" >0.612025</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col5\" class=\"data row0 col5\" >0.569269</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col6\" class=\"data row0 col6\" >0.532981</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col7\" class=\"data row0 col7\" >0.565920</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col8\" class=\"data row0 col8\" >0.559394</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col9\" class=\"data row0 col9\" >0.522520</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col10\" class=\"data row0 col10\" >0.568789</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col11\" class=\"data row0 col11\" >0.586311</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col12\" class=\"data row0 col12\" >0.514261</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col13\" class=\"data row0 col13\" >0.530421</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col14\" class=\"data row0 col14\" >0.524453</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col15\" class=\"data row0 col15\" >0.531299</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col16\" class=\"data row0 col16\" >0.492818</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row0_col17\" class=\"data row0 col17\" >0.515289</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col0\" class=\"data row1 col0\" >A single legal text representation at Doctrine: the legal camemBERT</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col1\" class=\"data row1 col1\" >As a legal platform, Doctrine aggregates a lot of legal data with the intent of making them accessible, understandable and usable. The Machine Learning Engineers’ day-to-day material is mostly text: court decisions, legislation, legal commentaries, user queries, etc. All of our content is natural language, which we process in a number of ways: bag-of-words, embeddings or with language models.In an ideal world though, our product would be built on top of scalable, flexible and reusable modules, ones that would be generic enough to accommodate a wide variety of legal contents and feed the whole spectrum of our product features. It is exactly with that vision in mind that we started working on a unified language model a few months ago, whose associated challenges, findings and results we’ll do our best to summarize in this article.I. One language model to rule them allDepending on the project, we were representing our legal contents with:different techniques:TF-IDF vectorsBM25 (e.g., with ElasticSearch)A variant of Word2Vec, called Wang2Vec, embeddings fine-tuned on legal data — note that even if those embeddings work pretty well for a lot of tasks, they are not the state-of-the-art anymore. There’s not enough modeling power in simple word embeddings and we definitely see their limits now on some tasks.2. different data:vocabulary of the content itself,vocabulary of the linked contents from our legal graphvocabulary from some metadata provided by the courts…Yet eventually, we want to be able to represent all of our legal content using a unified framework for any text-understanding based feature, because of:Reusability: all teams can rely on this unique language model for their projects.2. Scalability:a modeling power sufficient to be applied to any new legal content (e.g., legal documents from the lower house and the upper house),robust enough to unlock use cases we’re not yet considering, like legal bots, legal trend detection, argument mining, etc,generic enough to be applied to a new language (with a retraining on the new language of course).3. Agnostic usage: one of the problems with our current representations is that the text follows some guidelines in the way they phrase statements, and a textual similarity is thus strongly biased towards documents that have the same overall phrasing (of the same court for example), despite the fact they’re not invoking the same laws about the same thing. For example, it is now difficult for us to match decisions from the High Court/Court of Appeal to those from the Supreme Court simply because of their different writing styles (the former tends to focus primarily and precisely on the facts, while the latter favors usually only relies on the legal matter, which has an adverse effect on our current representations).When we initially started thinking about this, there were some properties that we thought our language model should ideally cover:Taking advantage of the semantic proximity:In French:préjudice corporel should be equivalent to dommage corporelIn English: death should be equivalent to loss of life2. Being able to represent our content on different granularities:Token-level for Named Entity Recognition: anonymization, entity detection, …Paragraph-level: structure detection, argument similarities, …Document-level: legal domain classification, document recommendation, …It’s with all those things in mind that we started to work on a unique, all-encompassing language model serving all our use cases and features.II. Our legal language modelThe first step of this project was to design the architecture and implementation of our language model. This step was crucial since it would serve as the foundation to all of our future work and help us move towards our initial vision. We first thought about our technical constraints:use an existing and robust implementation, in order to take advantage of the support and the community,use a state-of-the-art technique to achieve very good performances,ideally use a PyTorch implementation, because our previous Deep Learning algorithms were made with PyTorch. Moreover, PyTorch (along with a few others) remains the dominant deep learning library at the time of writing this article,if possible, find an implementation with a French pre-trained model before fine-tuning, because transfer learning has shown its efficiency in NLP.It should also be noted that compared to other use-cases, especially in academic research, the framework should be efficient at representing very long texts. Here is an interesting blog post about different document embeddings techniques. We’ll come to that later.Under these constraints, the Hugging Face Transformers library appeared to be a very good choice:they offer all the recent state-of-the-art architectures (BERT, RoBERTa, ELMo, XLNet, …) complete with their associated PyTorch and TensorFlow implementations,some of them have a French pre-trained model,their implementation has quickly become an international reference, to the point where the famous NLP framework Spacy provides a Transformer implementation based on the Hugging Face one.Among the models providing a French pre-trained model, we had the choice between:BERT-Base, multilingualDistilmBERT, multilingualcamemBERT, French RoBERTa modelWe decided to go for camemBERT, since it already provided good results for the French language on several tasks according to this paper. Of course, multilingual models will probably be very useful for internationalization later, but we initially wanted to check that a transformer model could be relevant. Moreover, camemBERT has fewer parameters than multilingual models, which makes it a little easier to use.Note that camemBERT is case-sensitive, which will be useful for Named Entity Recognition and especially for anonymization.The legal CamemBERTNow that we had settled on the underlying technology, we decided to check how well it would perform on actual, real-life legal data.Knowing that camemBERT was initially trained on the French subcorpus of OSCAR, which features gigabytes of data crawled from the web, we knew that it would fare well at general French language tasks, but we suspected that the task of speaking the more specific French legalese would prove to be a tougher nut to crack, which our initial tests confirmed.For example, when asked to predict the next word of the sentence Par ces ... , camemBERT suggested the word mots, which is not exactly legal-oriented. We would expect something like moyens or motifs.It was obvious at this point that the trove of millions of legal documents we have at our disposal at Doctrine would prove to be great material for the subsequent fine-tuning needed to harness the full power of our model. At this point, we were confident that the model could be trained, however, we needed it to be potentially used universally across features. Yet, one issue remained: how to handle long texts, a strong prerequisite for legal documents, but something that doesn’t pair naturally with transformers’ inherent limitations.BERT models, for example, have a hard limit of 512 to 514 tokens (as enforced by the max_position_embeddings parameter), which would surely be a challenge when dealing with court decisions: texts that can be infamously verbose, with an average token count hovering around 2000 (and some even more extreme cases like this decision).To circumvent this issue, we envisioned two different approaches:Embedding each paragraphHaving sliding windows, as explained hereTo avoid ending up with redundancy in the embeddings, we decided to go with paragraph embeddings first, with exceedingly long paragraphs getting snipped past the limit during training. What was left for us to determine at that point was an aggregation strategy over the different paragraphs, so that we could harvest the final document embeddings, something that we would come back to later.We then proceeded with the implementation, which was done by splitting our legal documents on paragraphs and fine-tuning camemBERT on the masked language model task (using dedicated AWS GPU instances). It converged after a few days and we tested its relevance by using a few qualitative checks:Comparison between the standard pre-trained French camemBERT model and our legal camemBERT on a masked LM taskWe assessed the differences in prediction for semantically similar sentences, which seemed to be consistent. The qualitative check seemed to provide very good results. It was now time to validate the language model on a real task.III. Our first legal camemBERT use-case: classification of legal domainWe wanted to try our legal camemBERT on a simple task for a first validation: text classification of legal domains on court decisions.This is indeed a simple and well delimited task, and easy to compare to other basic models. Moreover, this classification has a huge product impact, on the search filters, recommender systems and analytics.We have two hierarchies on the legal domains at Doctrine:the main legal domain:Droit civil,Droit commercial,Droit social,Droit public,…2. the subdomain: for example in Droit civil, there areDivorce et séparation de corpsDroit locatifDroit des successionsDroit de la responsabilité…Today, we support 9 different domains and 40 different subdomains, where some are more complex than others to determine. These categories have a hierarchical structure, but we addressed the problem by reducing it to a 40-class classification problem.The HuggingFace repository suggests a classification head module integrated with CamemBERT. However, as discussed earlier, the main problem is that court decisions can be very verbose (have a look at this very long decision for example), and BERT does not work well on long texts. A very good review of document embeddings showed that there are no clear embedding technique that works better than others for very long documents. It really depends on your objective.Working at a paragraph level seemed more relevant, all the more so as the language model has been trained at a paragraph scale. BERT will then provide an embedding for each paragraph. We then had to think about a way to aggregate the paragraphs in order to get a decision embedding.ModelingParagraph embeddings methodIt is known that BERT architectures provide not only word-level contextual embeddings but also the special CLS-token whose output embedding is used for classification tasks. However it turns out to be a poor embedding of the input sequence of other tasks if not fine-tuned on the specific task:The paper Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks from Reimers et al, 2019, shows that BERT out-of-the-box maps sentences to a vector space that is rather unsuitable to be used with common similarity measures like cosine-similarity.According to BERT creator Jacob Devlin: “I’m not sure what these vectors are, since BERT does not generate meaningful sentence vectors. It seems that this is is doing average pooling over the word tokens to get a sentence vector, but we never suggested that this will generate meaningful sentence representations.” sourceStill, the most classic ways to embed a document (in our case, a paragraph) with BERT are:to use the [CLS]-tokento use an aggregation of the last X hidden states of the word embeddings ( we usually saw X=4)What is interesting in our case is that one paragraph does not represent the whole court decision. We had to plug something on top of it. We decided to go with the [CLS]-token as paragraph embeddings for a first shot, because our task is a classification task.2. Document embedding with an aggregation over paragraphsGiven embeddings for all our paragraphs, we then had to think of a way to get document embeddings.Here again, different approaches can be considered, since this is another sequence-to-one vector modeling:A simple average of all paragraph embeddings (the [CLS]-token of each BERT-output paragraphs),A weighted average of the paragraph embeddings, with weights built with a self-attention mechanism explained in the paper A Structured Self-attentive Sentence Embedding,A bi-LSTM to exploit the sequential information contained in the paragraphs,A Convolutional Neural Network,Another BERT that would learn the language at the paragraph scale,…Given that our task is a mere classification problem, the solution with a self-attention mechanism seemed to be pretty relevant for our case because:It’s a bit smarter than a simple average-pooling, and it will automatically get rid of the useless paragraphs that contain no information for the legal domain. Indeed, the final paragraphs of French decisions are often related to the operative part of the judgment, and about who pays the costs. This is usually not relevant to our current problem.It also provides some precious insights on how to best interpret the model. We can indeed have access to the attention weights and check on which paragraphs the model focused on the most for its prediction.With all that mind, here’s the final architecture for the classification task:Final architecture of our legal document classification on documents, using the legal camemBERTWe first tried to train the whole pipeline, including the fine-tuning of the legal camemBERT on this task, but we got memory errors. We quickly froze the BERT model and trained only the rest of the pipeline (attention layer + classification layer). It provided good results so we didn’t go with further experiments on an end-to-end training. This is something that we made a note of though, since unsupervised BERT outputs are known to be poor if not fine-tuned, as discussed earlier in this article.ResultsThe goal here was not only to improve our legal domains classification, but also to show that we could achieve at least the same results as a simple TF-IDF model.Dataset creationDeep learning in general often requires a consequent training set size. That’s why we used a semi-automatically labelled training dataset, labelled:by humans, using Prodi.gywith business rules, using the associated court as a reference. If a decision is linked to another one from Labor court, it’s very likely that the decision is about Droit du travail(labor laws).with the most reliable predictions of our former algorithm, based on TF-IDF for the domain, and a legal taxonomy for the subdomain.Comparison between models and discussionWe achieved the same performance with our legal camemBERT and with a simple TF-IDF, which is actually good news! We indeed didn’t spend a lot of time on the modeling part of camemBERT, and this classification task is in the end a rather simple NLP task.Moreover and perhaps just as interestingly, we noticed after a qualitative analysis of model’s prediction errors that the errors of the simple model were more often out of context. It means that when the TF-IDF gets it wrong, it’s really way off the mark. For example, this decision is predicted as Droit du transport with a probability of 0.96, instead of Droit des assurances because the decision is about a vehicle insurance claim and contains a lot of vocabulary related to transportation, and not that much about insurance.On the other hand, the legal camemBERT can of course be wrong, but it never steers too much out of context and will mostly predict subdomains that are very close, like Droit immobilier et de la construction and Droit de la copropriété et de la propriété immobilière, when we look at the confusion matrix.Moreover, CamemBERT managed to predict some subdomains that were not obvious at all, even for humans. For example, this decision has been predicted as Divorce et séparations de corpswithout any explicit mention of the word divorce in the decision! The subdomain here is very implicit and implied by a mention to a father that has to pay alimony to the mother of his child.Let’s now have a look at the attention weights of our modeling. Here are some examples below:Paragraph with the highest attention score (0.34) for the prediction of https://www.doctrine.fr/d/CA/Reims/2008/SK60FC7292250FC0B001E6 as Divorce et Séparation de corpsParagraph with the highest attention score (0.26) for the prediction of https://www.doctrine.fr/d/CA/Rouen/2016/1F43DFAE32435B18DC90 as Droit des étrangers et de la nationalitéThese attention scores totally make sense, and confirmed the approach.We also confirmed that paragraphs related to generic procedures had a very low attention weight, like this one:Paragraph with a very low attention weight of 0.01 for the prediction of https://www.doctrine.fr/d/CA/Rouen/2016/1F43DFAE32435B18DC90 as Droit des étrangers et de la nationalitéFinally, when we had a look at the errors of the models (both models), we quickly noticed that some classes were very well predicted and some others were not. Our intuition about the observed discrepancy boils down to the fact that language models are only ever as good as their training dataset. In our case, the issue seems to stem from volume and errors in the training set. This is definitely the next priority for this task to focus on, before trying to play with the different architectures. Indeed, the current one seems to work pretty well on subdomains when the training dataset is satisfactory.ConclusionWe built a legal language model with a state-of-the-art technique, that proved to be very efficient at capturing highly relevant information on a simple classification task. This is a huge step for Doctrine, as we have a lot of very complex tasks in Natural Language Processing to tackle! The granularity of this new language model, which can seamlessly provide token, paragraph and document embeddings will be key for us to find new applications for the technique on a wide array of complex Natural Language Processing tasks at Doctrine.In fact, the legal camemBERT has already found a second problem to tackle with the issue of semantic similarity between users and legal content in the context of a recommendation system and seems to already have yielded promising results, which we’ll be sharing in an upcoming blog post very soon. Stay tuned!A single legal text representation at Doctrine: the legal camemBERT was originally published in Inside Doctrine on Medium, where people are continuing the conversation by highlighting and responding to this story.</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col2\" class=\"data row1 col2\" >https://medium.com/doctrine/a-single-legal-text-representation-at-doctrine-the-legal-camembert-a5ee2b851763?source=rss----8986dd8e9bad---4</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col3\" class=\"data row1 col3\" >0.570231</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col4\" class=\"data row1 col4\" >0.586314</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col5\" class=\"data row1 col5\" >0.521751</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col6\" class=\"data row1 col6\" >0.499045</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col7\" class=\"data row1 col7\" >0.548911</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col8\" class=\"data row1 col8\" >0.511261</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col9\" class=\"data row1 col9\" >0.517473</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col10\" class=\"data row1 col10\" >0.595577</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col11\" class=\"data row1 col11\" >0.505991</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col12\" class=\"data row1 col12\" >0.492187</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col13\" class=\"data row1 col13\" >0.509414</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col14\" class=\"data row1 col14\" >0.505175</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col15\" class=\"data row1 col15\" >0.512034</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col16\" class=\"data row1 col16\" >0.511341</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row1_col17\" class=\"data row1 col17\" >0.525712</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col0\" class=\"data row2 col0\" >[Q] Data scientist here, working on gathering a corpus of academic papers focusing on \"Cognitive Linguistics\". Need your help!</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col1\" class=\"data row2 col1\" >Hello. I want to collect as many as papers as I can that will fall into this category. The main problem is that the \"tagging\" is not consistent for linguistic papers. Hence I'm looking for an exhausitve list of tags which are directly related to this field, in order to make better queries and find more relevant data.  Thanks!    submitted by    /u/quit_daedalus   [link] [comments]</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col2\" class=\"data row2 col2\" >https://www.reddit.com/r/cognitivelinguistics/comments/ensu0n/q_data_scientist_here_working_on_gathering_a/</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col3\" class=\"data row2 col3\" >0.555300</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col4\" class=\"data row2 col4\" >0.578011</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col5\" class=\"data row2 col5\" >0.498356</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col6\" class=\"data row2 col6\" >0.489413</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col7\" class=\"data row2 col7\" >0.526189</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col8\" class=\"data row2 col8\" >0.513210</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col9\" class=\"data row2 col9\" >0.489906</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col10\" class=\"data row2 col10\" >0.544217</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col11\" class=\"data row2 col11\" >0.557324</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col12\" class=\"data row2 col12\" >0.480271</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col13\" class=\"data row2 col13\" >0.496461</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col14\" class=\"data row2 col14\" >0.485666</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col15\" class=\"data row2 col15\" >0.530694</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col16\" class=\"data row2 col16\" >0.496379</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row2_col17\" class=\"data row2 col17\" >0.504614</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col0\" class=\"data row3 col0\" >Dialogue State Induction Using Neural Latent Variable Models</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col1\" class=\"data row3 col1\" >Dialogue state modules are a useful component in a task-oriented dialogue system. Code: https://github.com/taolusi/dialogue-state-induction</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col2\" class=\"data row3 col2\" >https://paperswithcode.com/paper/dialogue-state-induction-using-neural-latent</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col3\" class=\"data row3 col3\" >0.609547</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col4\" class=\"data row3 col4\" >0.595336</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col5\" class=\"data row3 col5\" >0.546996</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col6\" class=\"data row3 col6\" >0.492073</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col7\" class=\"data row3 col7\" >0.601822</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col8\" class=\"data row3 col8\" >0.568787</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col9\" class=\"data row3 col9\" >0.546473</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col10\" class=\"data row3 col10\" >0.602195</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col11\" class=\"data row3 col11\" >0.570310</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col12\" class=\"data row3 col12\" >0.499499</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col13\" class=\"data row3 col13\" >0.532563</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col14\" class=\"data row3 col14\" >0.543948</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col15\" class=\"data row3 col15\" >0.563158</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col16\" class=\"data row3 col16\" >0.529331</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row3_col17\" class=\"data row3 col17\" >0.538693</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col0\" class=\"data row4 col0\" >Homotopic Gradients of Generative Density Priors for MR Image Reconstruction</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col1\" class=\"data row4 col1\" >Deep learning, particularly the generative model, has demonstrated tremendous potential to significantly speed up image reconstruction with reduced measurements recently. Code: https://github.com/yqx7150/WDAEPRec</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col2\" class=\"data row4 col2\" >https://paperswithcode.com/paper/homotopic-gradients-of-generative-density</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col3\" class=\"data row4 col3\" >0.635957</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col4\" class=\"data row4 col4\" >0.595485</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col5\" class=\"data row4 col5\" >0.585967</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col6\" class=\"data row4 col6\" >0.549362</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col7\" class=\"data row4 col7\" >0.571287</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col8\" class=\"data row4 col8\" >0.569784</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col9\" class=\"data row4 col9\" >0.528206</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col10\" class=\"data row4 col10\" >0.591445</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col11\" class=\"data row4 col11\" >0.553654</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col12\" class=\"data row4 col12\" >0.492025</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col13\" class=\"data row4 col13\" >0.538394</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col14\" class=\"data row4 col14\" >0.506285</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col15\" class=\"data row4 col15\" >0.529166</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col16\" class=\"data row4 col16\" >0.505183</td>\n",
       "                        <td id=\"T_bcc96e34_e2da_11ea_bf83_f4d108645659row4_col17\" class=\"data row4 col17\" >0.527197</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5060c3ea90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head().style.background_gradient(cmap=cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
